# ğŸ“ No Caffeine No Gain
<br>

**í”„ë¡œì íŠ¸ ê¸°ê°„ : 2021.05.31 ~ 2021.06.15**
<br>
<br>
**í”„ë¡œì íŠ¸ ë‚´ìš© : Deep Knowledge Tracing**

<br>

## [ëª©ì°¨]

- [\[Deep Knowledge Tracing ì†Œê°œ\]](#deep-knowledge-tracing-ì†Œê°œ)
- [[Installation]](#installation)
  * [Dependencies](#dependencies)
- [[Usage]](#usage)
  * [Dataset](#dataset)
  * [Train](#train)
  * [Inference](#inference)
  * [Arguments](#arguments)
- [[File Structure]](#file-structure)
  * [LSTM](#lstm)
  * [LSTMATTN](#lstmattn)
  * [BERT](#bert)
  * [LGBM](#lgbm)
  * [SAINT](#saint)
  * [LastQuery](#lastquery)
  * [TABNET](#tabnet)
- [[Input CSV File]](#input-csv-file)
- [[Feature]](#feature)
- [[Contributors]](#contributors)
- [[Collaborative Works]](#collaborative-works)
  * [ğŸ“ Notion](#-notion)
- [[Reference]](#reference)
  * [Papers](#papers)
  * [Dataset](#dataset-1)

<br>
<br>

## [Deep Knowledge Tracing ì†Œê°œ]

**DKT**ëŠ” **Deep Knowledge Tracing**ì˜ ì•½ìë¡œ ìš°ë¦¬ì˜ "ì§€ì‹ ìƒíƒœ"ë¥¼ ì¶”ì í•˜ëŠ” ë”¥ëŸ¬ë‹ ë°©ë²•ë¡ ì…ë‹ˆë‹¤.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d7568542-7435-4668-8267-495eaeb5d6ba/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d7568542-7435-4668-8267-495eaeb5d6ba/Untitled.png)

ëŒ€íšŒì—ì„œëŠ” í•™ìƒ ê°œê°œì¸ì˜ ì´í•´ë„ë¥¼ ê°€ë¦¬í‚¤ëŠ” ì§€ì‹ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì¼ë³´ë‹¤ëŠ”, ì£¼ì–´ì§„ ë¬¸ì œë¥¼ ë§ì¶œì§€ í‹€ë¦´ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/447fe89e-5e3d-4024-ac80-7a125870a8f0/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/447fe89e-5e3d-4024-ac80-7a125870a8f0/Untitled.png)

<br>
<br>

## [Installation]

### Dependencies

- torch
- pandas
- sklearn
- pycaret
- tqdm
- wandb
- easydict

```bash
pip install -r requirements.txt
```

<br>
<br>

## [Usage]

### Dataset

í•™ìŠµì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë‘ ê°œì˜ `.py` íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
$ p4-dkt-no_caffeine_no_gain# python make_elapsed.py
$ p4-dkt-no_caffeine_no_gain# python make_fixed_data.py
```

### Train

ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” `train.py` ë¥¼ ì‹¤í–‰ì‹œí‚µë‹ˆë‹¤.

ì•„ë˜ Arguments ì— ìˆëŠ” argument ì¤‘ í•„ìš”í•œ argumet ë¥¼ ë°”ê¿” ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

```bash
$ p4-dkt-no_caffeine_no_gain# python train.py
```

ì´ 7ê°€ì§€ì˜ ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **TABNET**
- **LASTQUERY**
- **SAINT**
- **LGBM**
- **BERT**
- **LSTMATTN**
- **LSTM**

### Inference

í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ê¸° ìœ„í•´ì„œëŠ” `inference.py` ë¥¼ ì‹¤í–‰ì‹œí‚µë‹ˆë‹¤.

í•„ìš”í•œ argument ëŠ” `â€”-model_name` ê³¼ `â€”-model_epoch` ì…ë‹ˆë‹¤.

```bash
$ p4-dkt-no_caffeine_no_gain# python inference.py --model_name "í•™ìŠµí•œ ëª¨ë¸ í´ë” ì´ë¦„" --model_epoch "ì‚¬ìš©í•˜ê³ í”ˆ ëª¨ë¸ì˜ epoch"
```

### Arguments

train ê³¼ inference ì—ì„œ í•„ìš”í•œ argument ì…ë‹ˆë‹¤.

```python
# Basic
--model: model type (default:'lstm')
--scheduler: scheduler type (default:'plateau')
--device: device to use (defualt:'cpu')
--data_dir: data directory (default:'/opt/ml/input/data/train_dataset')
--asset_dir: asset directory (default:'asset/')
--train_file_name: train file name (default:'add_FE_fixed_train.csv')
--valid_file_name: validation file name (default:'add_FE_fixed_valid.csv')
--test_file_name: test file name (default:'add_FE_fixed_test.csv')
--model_dir: model directory (default:'models/')
--num_workers: number of workers (default:1)
--output_dir: output directory (default:'output/')
--output_file: output file name (default:'output')
--model_name: model folder name (default:'')
--model_epoch: model epoch to use (default:1)

# Hyperparameters
--seed: random state (default:42)
--optimizer: optimizer type (default:'adamW')
--max_seq_len: max sequence length (default:20)
--hidden_dim: hidden dimension size (default:64)
--n_layers: number of layers (default:2)
--n_epochs: number of epochs (default:20)
--batch_size: batch size (default:64)
--lr: learning rate (default:1e-4)
--clip_grad: clip grad (default:10)
--patience: for early stopping (default:5)
--drop_out: drop out rate (default:0.2)
--dim_div: hidden dimension dividor in model to prevent too be large scale (default:3)

# Transformer
--n_heads: number of heads (default:2)
--is_decoder: use transformer decoder (default:True)

# TabNet
--tabnet_pretrain: Using TabNet pretrain (default:False)
--use_test_to_train: to training includes test data (default:False)
--tabnet_scheduler: TabNet scheduler (default:'steplr')
--tabnet_optimizer: TabNet optimizer (default:'adam')
--tabnet_lr: TabNet learning rate (default:2e-2)
--tabnet_batchsize: TabNet batchsize (default:16384)
--tabnet_n_step: TabNet n step(not log step) (default:5)
--tabnet_gamma: TabNet gamma (default:1.7)
--tabnet_mask_type: TabNet mask type (default:'saprsemax')
--tabnet_virtual_batchsize: TabNet virtual batchsize (default:256)
--tabnet_pretraining_ratio: TabNet pretraining ratio (default:0.8)

# Sliding Window
--window: Using Sliding Window augmentation (default:False)
--shuffle: shuffle Sliding Window (default:False)
--stride: Sliding Window stride (default:20)
--shuffle_n: Shuffle times (default:1)

# T-Fixup
--Tfixup: Using T-Fixup (default:False)
--layer_norm: T-Fixup with layer norm (default:False)

# Pseudo Labeling
--use_pseudo: Using Pseudo Labeling (default:False)
--pseudo_label_file: file path for Pseudo Labeling (default:'')

# log
--log_steps: print log per n steps (default:50)

# wandb
--use_wandb: if you want to use wandb (default:True)
```

## [File Structure]

ì „ì²´ì ì¸ File Structure ì…ë‹ˆë‹¤.

```
code
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ args.py
â”œâ”€â”€ make_custom_data
â”‚   â”œâ”€â”€ make_elapsed.py - time ê´€ë ¨ feature ìƒì„±
â”‚   â”œâ”€â”€ make_fixed_data.py - user ì •ë‹µë¥  ê¸°ë°˜ìœ¼ë¡œ valid ìƒì„±
â”‚   â””â”€â”€ make_original_fixed_data.py - shuffleí•´ì„œ valid ìƒì„±
â”‚
â”œâ”€â”€ dkt
â”‚   â”œâ”€â”€ criterion.py
â”‚   â”œâ”€â”€ dataloader.py
â”‚   â”œâ”€â”€ metric.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ optimizer.py
â”‚   â”œâ”€â”€ scheduler.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ ensemble.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ requirements.txt - dependencies
â””â”€â”€ train.py

```

<br>
<br>

### LSTM

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2fd4ada4-6d16-4bb5-bf41-2e34795347b4/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2fd4ada4-6d16-4bb5-bf41-2e34795347b4/Untitled.png)

- sequence dataë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ LSTM ëª¨ë¸ì…ë‹ˆë‹¤.
- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class LSTM
    â”‚   â”œâ”€â”€ init()
    â””â”€â”€ â””â”€â”€ forward() : return predicts

    args.py
    â”œâ”€â”€ args.max_seq_len(default : 20)
    â”œâ”€â”€ args.n_layers(default : 2)
    â”œâ”€â”€ args.n_heads(default : 2)
    â””â”€â”€ args.hidden_dim(default : 64)
    ```

<br>
<br>

### LSTMATTN

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5c335562-4ff2-46b4-a3a5-728021a548e7/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5c335562-4ff2-46b4-a3a5-728021a548e7/Untitled.png)

- LSTM ëª¨ë¸ì— Self-Attentionì„ ì¶”ê°€í•œ ëª¨ë¸ì…ë‹ˆë‹¤.
- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class LSTMATTN
    â”‚   â”œâ”€â”€ init()
    â””â”€â”€ â””â”€â”€ forward() : return predicts

    args.py
    â”œâ”€â”€ args.max_seq_len(default : 20)
    â”œâ”€â”€ args.n_layers(default : 2)
    â”œâ”€â”€ args.n_heads(default : 2)
    â””â”€â”€ args.hidden_dim(default : 64)
    ```

<br>
<br>

### BERT

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/eace3214-70f5-4bc3-9267-f5940d59551c/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/eace3214-70f5-4bc3-9267-f5940d59551c/Untitled.png)

- `Huggingface` ì—ì„œ BERT êµ¬ì¡°ë¥¼ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ë§Œ, pre-trained ëª¨ë¸ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— Transformer-encoder ì™€ ê°™ìŠµë‹ˆë‹¤.
- í˜„ì¬ ëª¨ë¸ì—ì„œëŠ” bert_config ì˜ is_decoder ë¥¼ True ë¡œ ì£¼ì–´ Transformer-decoder ë¡œ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class Bert
    â”‚   â”œâ”€â”€ init()
    â””â”€â”€ â””â”€â”€ forward() : return predicts

    args.py
    â”œâ”€â”€ args.max_seq_len(default : 20)
    â”œâ”€â”€ args.n_layers(default : 2)
    â”œâ”€â”€ args.n_heads(default : 2)
    â”œâ”€â”€ args.is_decoder(default : True)
    â””â”€â”€ args.hidden_dim(default : 64)
    ****
    ```

<br>
<br>

### LGBM

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cbf5c2b5-1aff-4428-983b-413da3a5ebbe/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cbf5c2b5-1aff-4428-983b-413da3a5ebbe/Untitled.png)

- tabular dataì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” Machine Learning ëª¨ë¸ì…ë‹ˆë‹¤.

<br>
<br>

### SAINT

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0682e128-c43a-4940-8481-ffc3faa43e71/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0682e128-c43a-4940-8481-ffc3faa43e71/Untitled.png)

- Kaggle Riiid AIEd Challenge 2020ì˜ [Hostê°€ ì œì‹œí•œ solution](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/193250) ì…ë‹ˆë‹¤.
- Transformerì™€ ë¹„ìŠ·í•œ êµ¬ì¡°ì˜ ëª¨ë¸ë¡œ Encoderì™€ Decoderë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
- ì¸ì½”ë”ëŠ” feature ì„ë² ë”© ìŠ¤íŠ¸ë¦¼ì— self-attention ë ˆì´ì–´ë¥¼ ì ìš©í•˜ê³  ë””ì½”ë”ì—ì„œ self-attention ë ˆì´ì–´ì™€ ì¸ì½”ë”-ë””ì½”ë” attention ë ˆì´ì–´ë¥¼ ì‘ë‹µ ì„ë² ë”©ê³¼ ì¸ì½”ë”ì˜ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ì— ë²ˆê°ˆì•„ ì ìš©í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
- **Paper Review : [[**Saint ëª¨ë¸ ë¶„ì„]](https://www.notion.so/Saint-507d13692825492ba05128f4548c2da7)
- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class Saint
    â”‚   â”œâ”€â”€ init()
    â””â”€â”€ â””â”€â”€ forward() : return predicts

    args.py
    â”œâ”€â”€ args.max_seq_len(default : 20)
    â”œâ”€â”€ args.n_layers(default : 2)
    â”œâ”€â”€ args.n_heads(default : 2)
    â””â”€â”€ args.hidden_dim(default : 64)
    ```

<br>
<br>

### LastQuery

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d4beb986-59f0-4b68-8156-5dd6ee283256/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d4beb986-59f0-4b68-8156-5dd6ee283256/Untitled.png)

- Kaggle Riiid AIEd Challenge 2020ì˜ [1st place solution](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/218318)ì…ë‹ˆë‹¤.
- transformer encoderì˜ ì…ë ¥ìœ¼ë¡œ sequenceì˜ ë§ˆì§€ë§‰ queryë§Œ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ë³µì¡ë„ë¥¼ ì¤„ì´ê³ , encoderì˜ outputì„ LSTMì— ë„£ì–´ í•™ìŠµí•˜ëŠ” ë°©ì‹ì˜ ëª¨ë¸ì…ë‹ˆë‹¤.
- **Paper Review :**  [[Last Query Transformer RNN for knowledge tracing ë¦¬ë·°]](https://www.notion.so/Last-Query-Transformer-RNN-for-knowledge-tracing-e0930bfff69b4d2e852de4cbd8e44678)
- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class LastQuery
    â”‚   â”œâ”€â”€ init()
    â””â”€â”€ â””â”€â”€ forward() : return predicts

    args.py
    â”œâ”€â”€ args.max_seq_len(default : 20)
    â”œâ”€â”€ args.n_layers(default : 2)
    â”œâ”€â”€ args.n_heads(default : 2)
    â”œâ”€â”€ args.hidden_dim(default : 64)
    â””â”€â”€ args.Tfixup(default : False)
    ```

<br>

<br>

### TABNET

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a4d49173-70b9-43b1-91f3-3051250e5e4d/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a4d49173-70b9-43b1-91f3-3051250e5e4d/Untitled.png)

- tabular dataì—ì„œ MLëª¨ë¸ë³´ë‹¤ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” Deep-learning modelì…ë‹ˆë‹¤.
- dataì—ì„œ Sparse instance-wise feature selectionì„ ì‚¬ìš©í•˜ì—¬ ìì²´ì ìœ¼ë¡œ ì¤‘ìš”í•œ feature ì„ ë³„í•´ë‚¸ í›„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•˜ë©°, feature ì„ ë³„ì‹œ non-linearí•œ processingì„ ì‚¬ìš©í•˜ì—¬ learning capacityë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- Sequentialí•œ multi-step architectureë¥¼  ê°€ì§€ê³ ìˆìœ¼ë©°, feature maskingìœ¼ë¡œ Unsupervised í•™ìŠµë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- **Paper Review : [[Tabnet ë…¼ë¬¸ ë¦¬ë·°]](https://www.notion.so/Tabnet-298eca48c26a4486a4df8e1586cba2ed)**

- **êµ¬í˜„**

    ```
    model.py
    â”œâ”€â”€ class TabNet
    â”‚   â”œâ”€â”€ TabNetPreTrainer
    â”‚   â”œâ”€â”€ TabNetClassifier
    â”‚   â”œâ”€â”€ get_scheduler()
    â”‚   â”œâ”€â”€ get_optimizer()
    â””â”€â”€ â””â”€â”€ forward() : return models

    trainer.py
    â”œâ”€â”€ tabnet_run(args, train_data, valid_data)
    â”œâ”€â”€ get_tabnet_model(args)
    â””â”€â”€ tabnet_inference(args, test_data)

    train.py
    â””â”€â”€ tabnet_run()

    args.py
    â”œâ”€â”€ args.tabnet_pretrain(default : False)
    â”œâ”€â”€ args.use_test_to_train(default : False)
    ****â”œâ”€â”€ args.tabnet_scheduler(default:'steplr')
    ****â”œâ”€â”€ args.tabnet_optimizer(default:'adam')
    ****â”œâ”€â”€ args.tabnet_lr(default:2e-2)
    ****â”œâ”€â”€ args.tabnet_batchsize(default:16384)
    ****â”œâ”€â”€ args.tabnet_n_step(default:5)
    ****â”œâ”€â”€ args.tabnet_gamma(default:1.7)
    â”œâ”€â”€ args.tabnet_mask_type(default:'saprsemax')
    â”œâ”€â”€ args.tabnet_virtual_batchsize(default:256)
    â””â”€â”€ args.tabnet_pretraining_ratio(default:0.8)
    ****
    ```

<br>

## [Input CSV File]

ë°ì´í„°ëŠ” ì•„ë˜ì™€ ê°™ì€ í˜•íƒœì´ë©°, í•œ í–‰ì€ í•œ ì‚¬ìš©ìê°€ í•œ ë¬¸í•­ì„ í’€ì—ˆì„ ë•Œì˜ ì •ë³´ì™€ ê·¸ ë¬¸í•­ì„ ë§ì·„ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ë‹´ê²¨ì ¸ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ëŠ” ëª¨ë‘ Timestamp ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0b52081c-e41b-41eb-9417-dc319de4e93b/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0b52081c-e41b-41eb-9417-dc319de4e93b/Untitled.png)

- `userID` ì‚¬ìš©ìì˜ ê³ ìœ ë²ˆí˜¸ì…ë‹ˆë‹¤. ì´ 7,442ëª…ì˜ ê³ ìœ  ì‚¬ìš©ìê°€ ìˆìœ¼ë©°, train/testì…‹ì€ ì´ `userID`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 90/10ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ì–´ì¡ŒìŠµë‹ˆë‹¤.
- `assessmentItemID` ë¬¸í•­ì˜ ê³ ìœ ë²ˆí˜¸ì…ë‹ˆë‹¤. ì´ 9,454ê°œì˜ ê³ ìœ  ë¬¸í•­ì´ ìˆìŠµë‹ˆë‹¤.
- `testId` ì‹œí—˜ì§€ì˜ ê³ ìœ ë²ˆí˜¸ì…ë‹ˆë‹¤. ë¬¸í•­ê³¼ ì‹œí—˜ì§€ì˜ ê´€ê³„ëŠ” ì•„ë˜ ê·¸ë¦¼ì„ ì°¸ê³ í•˜ì—¬ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì´ 1,537ê°œì˜ ê³ ìœ í•œ ì‹œí—˜ì§€ê°€ ìˆìŠµë‹ˆë‹¤.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dc01d187-575e-4c0e-bddb-5eec928e86db/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/dc01d187-575e-4c0e-bddb-5eec928e86db/Untitled.png)

- `answerCode` ì‚¬ìš©ìê°€ í•´ë‹¹ ë¬¸í•­ì„ ë§ì·„ëŠ”ì§€ ì—¬ë¶€ì— ëŒ€í•œ ì´ì§„ ë°ì´í„°ì´ë©° 0ì€ ì‚¬ìš©ìê°€ í•´ë‹¹ ë¬¸í•­ì„ í‹€ë¦° ê²ƒ, 1ì€ ì‚¬ìš©ìê°€ í•´ë‹¹ ë¬¸í•­ì„ ë§ì¶˜ ê²ƒì…ë‹ˆë‹¤.
- `Timestamp` ì‚¬ìš©ìê°€ í•´ë‹¹ë¬¸í•­ì„ í’€ê¸° ì‹œì‘í•œ ì‹œì ì˜ ë°ì´í„°ì…ë‹ˆë‹¤.
- `KnowledgeTag` ë¬¸í•­ ë‹¹ í•˜ë‚˜ì”© ë°°ì •ë˜ëŠ” íƒœê·¸ë¡œ, ì¼ì¢…ì˜ ì¤‘ë¶„ë¥˜ ì—­í• ì„ í•©ë‹ˆë‹¤. íƒœê·¸ ìì²´ì˜ ì •ë³´ëŠ” ë¹„ì‹ë³„í™” ë˜ì–´ìˆì§€ë§Œ, ë¬¸í•­ì„ êµ°ì§‘í™”í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 912ê°œì˜ ê³ ìœ  íƒœê·¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.

## [Feature]

```python
elapsed: ìœ ì €ê°€ ë¬¸ì œë¥¼ í‘¸ëŠ”ë°ì— ì†Œìš”í•œ ì‹œê°„

time_bin: ë¬¸ì œë¥¼ í‘¼ ì‹œê°„ëŒ€(ì•„ì¹¨, ì ì‹¬, ì €ë…, ìƒˆë²½)

classification: ëŒ€ë¶„ë¥˜(í•™ë…„)

paperNum: ì‹œí—˜ì§€ ë²ˆí˜¸

problemNum: ë¬¸ì œ ë²ˆí˜¸

user_total_acc: ìœ ì €ì˜ ì´ ì •ë‹µë¥ 

test_acc: ê° ì‹œí—˜ì§€ì˜ í‰ê·  ì •ë‹µë¥ 

assessment_acc: ê° ë¬¸ì œì˜ í‰ê·  ì •ë‹µë¥ 

tag_acc: ê° íƒœê·¸ì˜ í‰ê·  ì •ë‹µë¥ 

total_used_time: ìœ ì €ê°€ í•˜ë‚˜ì˜ ì‹œí—˜ì§€ë¥¼ ë‹¤ í‘¸ëŠ”ë°ì— ì†Œìš”í•œ ì‹œê°„

past_correct: ìœ ì €ë³„ ê³¼ê±° ë§ì¶˜ ë¬¸ì œì˜ ìˆ˜

past_content_count: ìœ ì €-ë¬¸ì œë³„ ê³¼ê±°ì— ë™ì¼ ë¬¸ì œë¥¼ ë§Œë‚œ íšŸìˆ˜

correct_per_hour: ì‹œê°„(hours)ë³„ ì •ë‹µë¥ 

same_tag: ë™ì¼ íƒœê·¸ë¥¼ ì—°ì†ìœ¼ë¡œ í’€ì—ˆëŠ”ì§€ ìœ ë¬´(T/F)

cont_tag: ì—°ì†ìœ¼ë¡œ í‘¼ ë™ì¼ íƒœê·¸ ê°œìˆ˜(0~)

etc...
```

<br>
<br>


## [Contributors]

- **ì •í¬ì„** ([Heeseok-Jeong](https://github.com/Heeseok-Jeong))
- **ì´ì• ë‚˜** ([Anna-Lee](https://github.com/ceanna93))
- **ì´ì°½ìš°** ([changwoomon](https://github.com/changwoomon))
- **ì•ˆìœ ì§„** ([dkswndms4782](https://github.com/dkswndms4782))
- **ì„ ì¬ìš°** ([JAEWOOSUN](https://github.com/JAEWOOSUN))

<br>
<br>

## [Collaborative Works]

**Gitflow ë¸Œëœì¹˜ ì „ëµ**

`â†’ 92ê°œì˜ Commits, 26ê°œì˜ Pull Requests`

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/51d09511-77c0-4efe-a65b-c706cae75ecd/pr.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/51d09511-77c0-4efe-a65b-c706cae75ecd/pr.gif)

<br>

**Github issues & projects ë¡œ ì¼ì • ê´€ë¦¬**

`â†’ 28ê°œì˜ Issues`

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/38005daf-d372-403f-b7b7-5d162d11bc57/ezgif.com-gif-maker.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/38005daf-d372-403f-b7b7-5d162d11bc57/ezgif.com-gif-maker.gif)

`â†’ Modeling Project ì—ì„œ ê´€ë¦¬`

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f937a7c8-19d5-4e52-a49a-68d3843be5b6/project.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f937a7c8-19d5-4e52-a49a-68d3843be5b6/project.gif)

<br>

**Notion ì‹¤í—˜ë…¸íŠ¸ë¡œ ì‹¤í—˜ ê³µìœ **

`â†’ 39ê°œì˜ ì‹¤í—˜ë…¸íŠ¸`

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0280f6aa-f632-4155-b7b8-c3d5b7b02a8b/.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0280f6aa-f632-4155-b7b8-c3d5b7b02a8b/.gif)

<br>

**Notion ì œì¶œê¸°ë¡ìœ¼ë¡œ ì œì¶œ ë‚´ì—­ ê³µìœ **

`â†’ 155ê°œì˜ ì œì¶œê¸°ë¡`

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fc10b2d9-5768-4fab-98ac-a76a131fd492/.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fc10b2d9-5768-4fab-98ac-a76a131fd492/.gif)

<br>

### ğŸ“ Notion

í”¼ì–´ë“¤ì˜ `Ground Rule`, `ì‹¤í—˜ë…¸íŠ¸`, `í”¼ì–´ì„¸ì…˜` ë“± í•œë‹¬ ê°„ì˜ í–‰ë³´ë¥¼ í™•ì¸í•˜ì‹œë ¤ë©´ ë‹¤ìŒ ë§í¬ë¥¼ í´ë¦­í•˜ì„¸ìš”.

* LINK : [DKT-10ì¡°-No_Caffeine_No_Gain](https://www.notion.so/DKT-10-No_Caffeine_No_Gain-dcc1e3823ec849578ab5ae0bcf117145)

<br>
<br>

## [Reference]

### Papers

- [Deep Knowledge Tracing (Piech et al., arXiv 2015)](https://arxiv.org/pdf/1506.05908.pdf)
- [Last Query Transformer RNN for Knowledge Tracing (Jeon, S., arXiv 2021)](https://arxiv.org/abs/2102.05038)
- [Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing (Choi et al., arXiv 2021)](https://arxiv.org/abs/2002.07033)
- [How to Fine-Tune BERT for Text Classification? (Sun et al., arXiv 2020)](https://arxiv.org/pdf/1905.05583.pdf)
- [Improving Transformer Optimization Through Better Initialization (Huang et al., ICML 2020)](https://www.cs.toronto.edu/~mvolkovs/ICML2020_tfixup.pdf)

### Dataset
- i-Scream edu Dataset
![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/59ea867b-83f2-4bba-ae0d-e40cadd59c18/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/59ea867b-83f2-4bba-ae0d-e40cadd59c18/Untitled.png)
